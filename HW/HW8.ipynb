{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 8\n",
    "\n",
    "This assignment covers all fundamental concepts required for completing a project\n",
    "\n",
    "**DO NOT ERASE MARKDOWN CELLS AND INSTRUCTIONS IN YOUR HW submission**\n",
    "  * **Q** - QUESTION\n",
    "  * **A** - Where to input your answer\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Keep the following in mind for all notebooks you develop:\n",
    "* Structure your notebook. \n",
    "* Use headings with meaningful levels in Markdown cells, and explain the questions each piece of code is to answer or the reason it is there.\n",
    "* Make sure your notebook can always be rerun from top to bottom.\n",
    "* Please start working on this assignment as soon as possible. If you are a beginner in Python this might take a long time. One of the objectives of this assignment is to help you learn python and scikit-learn package. \n",
    "* See [README.md](README.md) for homework submission instructions\n",
    "\n",
    "## Related Tutorials\n",
    "\n",
    "### Refreshers\n",
    "* [Intro to Machine Learning w scikit-learn](https://scikit-learn.org/stable/tutorial/basic/tutorial.html)\n",
    "* [A tutorial on statistical-learning for scientific data processing](https://scikit-learn.org/stable/tutorial/statistical_inference/index.html#stat-learn-tut-index)\n",
    " \n",
    "### Classification Approaches\n",
    "* [Logistic Regression with Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "* [KNN with sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "* [Support Vector machine example](https://scikit-learn.org/stable/auto_examples/exercises/plot_iris_exercise.html#sphx-glr-auto-examples-exercises-plot-iris-exercise-py)\n",
    "* [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html?highlight=svc#sklearn.svm.SVC)\n",
    "* [Bagging Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)\n",
    "* [Gradient Boosting Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
    "  \n",
    "### Modeling   \n",
    "* [Cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "* [Plot Confursion Matrix with Sklearn](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html)\n",
    "* [Confusion Matrix Display](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all required library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "import json\n",
    "import lightgbm as lgbm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1** Get training data from the dataframe\n",
    "1. Load ```HW8_data.csv``` from ```data``` folder into data frame\n",
    "2. Print the head of the dataframe\n",
    "3. Print the shape of the dataframe\n",
    "4. Print the description of the dataframe\n",
    "5. Assign ```Cover_Type``` values to Y\n",
    "6. Assign rest of the column values to X\n",
    "\n",
    "**A1** Fill the cell blocks below, Create new cell as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can create or remove cells as per your need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=\n",
    "Y="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** Observe the range of all feature values from the dataframe description above. \n",
    "1. Do you think in our dataset normalization is required? -- Give proper justification based on your opinion. \n",
    "2. What type of normalization/Scaling technique you whould recommend for our dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A2** \n",
    "\n",
    "```Answer 1:``` \n",
    "\n",
    "```Answer 2:```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3:** \n",
    "1. Use the above mentioned normalization technique on our HW_8 dataset.\n",
    "2. Transform the X dataframe using choosen normalization technique. \n",
    "\n",
    "### ```Note:``` Make sure the scaled X has all column name same as ```X dataframe```\n",
    "\n",
    "**A3** Fill the cell blocks below, Create new cell as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can create or remove cells as per your need\n",
    "Scaled_X = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4:** \n",
    "\n",
    "1. Check and show if there is any null values in our dataset.\n",
    "2. Print all unique values/ different class id from the ```Y data```.\n",
    "\n",
    "\n",
    "**A4** Fill the cell blocks below, Create new cell as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can create or remove cells as per your need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Use a subset of whole data(N=20000) for Data Visualization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Subset Creation**\n",
    "\n",
    "1. First we are Selecting ```N=20000``` random rows from our original dataset which is ```df``` and create a new subset of data.\n",
    "\n",
    "2. Using the below **rndperm** and selecting first N index from the ```Scaled_X``` and ```Y```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "rndperm = np.random.permutation(df.shape[0])\n",
    "N = 20000\n",
    "data_subset_x = Scaled_X.loc[rndperm[:N],:].copy()\n",
    "data_subset_y = Y.loc[rndperm[:N]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5:**\n",
    "\n",
    "1. Use PCA and reduce the dimension of the **data_subset_x** into ```3```.\n",
    "2. Store the PCA reuslt into ```pca_result``` variable\n",
    "3. Add the resutls from the PCA into the **data_subset_x** as new columns. (Choose any meaningful names for the columns) \n",
    "\n",
    "\n",
    "**A5** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can create or remove cells as per your need\n",
    "pca = \n",
    "pca_result = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?\n",
    "?\n",
    "?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6:**\n",
    "\n",
    "1. Use TSNE and reduce the dimension of the **data_subset_x** into ```2```.\n",
    "2. Store the TSNE reuslt into ```tsne_results``` variable\n",
    "3. Add the resutls from the T-SNE into the **data_subset_x** as new columns. (Choose any meaningful names for the columns) \n",
    "\n",
    "\n",
    "```Note:``` \n",
    "1. You can use ```from sklearn.manifold import TSNE``` for TSNE initialization.\n",
    "2. Give value of n_components as per the question.\n",
    "3. Also use other parameters while TSNE initialization as, ```verbose=1, perplexity=40, n_iter=300```\n",
    "\n",
    "**A6** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can create or remove cells as per your need\n",
    "tsne =\n",
    "tsne_results = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?\n",
    "?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7:**\n",
    "\n",
    "1. Create a new dataframe with name ```df_plot```\n",
    "2. This dataframe will merge everything from **data_subset_x** and **data_subset_y**\n",
    "3. We need to give a name for the ```data_subset_y``` column. Use ```Cover_Type``` as the name of the column\n",
    "\n",
    "\n",
    "**A7** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot=\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8:** Now we will plot all points from our dataframe ```df_plot``` Using the result from **PCA**\n",
    "\n",
    "1. Use ```pca-one``` and ```pca-two``` column as X and Y axis respectively.\n",
    "2. Use seaborn scatterplot for plotting the points.\n",
    "\n",
    "```Note:``` Use the notebook from class for reference. The link is provided below.\n",
    "\n",
    "```Link:``` https://git.txstate.edu/ML/2022Fall/blob/main/project/Data_Viz_with_PCA_TSNE.ipynb\n",
    "\n",
    "**A8** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9:** Now we will plot all points from our dataframe ```df_plot``` Using result from T-SNE.\n",
    "\n",
    "1. Use ```tsne-2d-one``` and ```tsne-2d-one``` column as X and Y axis respectively.\n",
    "2. Use seaborn scatterplot for plotting the points.\n",
    "\n",
    "\n",
    "```Note:``` Use the notebook from class for reference. The link is provided below.\n",
    "\n",
    "```Link:``` https://git.txstate.edu/ML/2022Fall/blob/main/project/Data_Viz_with_PCA_TSNE.ipynb\n",
    "\n",
    "**A9** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Analysis and Classification Using Entire Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10:** Observe the data plotting and find the realtion between datapoints and their characteristics.\n",
    "\n",
    "\n",
    "1. Reduce the dimension of our ```Scaled_X``` dataframe to ```3``` using PCA algorithm.\n",
    "2. Store the result into a variable named ```pca_result```\n",
    "3. Create Train data and Test data using the pca_result and Y.\n",
    "\n",
    "```Note:``` \n",
    "1. Consider pca_result as X values, and Y as y values.\n",
    "2. You can use sklearn train_test_split\n",
    "3. Keep Train and Test ratio as : 75%:25%\n",
    "\n",
    "**A10** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can create or remove cells as per your need\n",
    "pca = \n",
    "pca_result = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, Select Three best model for our dataset. You have to decide three models which might work well with our dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NsUM8-i_KhK1"
   },
   "source": [
    "**Q11** \n",
    "\n",
    "**Model Number 1** \n",
    "\n",
    "1. Reason behind choosing the model.\n",
    "2. Create the model using sklearn or any proper library\n",
    "3. Fit the model with the train data \n",
    "4. Get the score from the model using test data\n",
    "\n",
    "**A11** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Answer for Q.No:1 goes here```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QutY2XJWps5"
   },
   "outputs": [],
   "source": [
    "#You can create or remove cells as per your need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12** \n",
    "\n",
    "**Model Number 2** \n",
    "\n",
    "1. Reason behind choosing the model.\n",
    "2. Create the model using sklearn or any proper library\n",
    "3. Fit the model with the train data \n",
    "4. Get the score from the model using test data\n",
    "\n",
    "**A12** Fill the below cells. Use extra cells as per your necessaryReplace ??? with code in the code cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Answer for Q.No:1 goes here```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13** \n",
    "\n",
    "**Model Number 3** \n",
    "\n",
    "1. Reason behind choosing the model.\n",
    "2. Create the model using sklearn or any proper library\n",
    "3. Fit the model with the train data \n",
    "4. Get the score from the model using test data\n",
    "\n",
    "**A13** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Answer for Q.No:1 goes here```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14** \n",
    "\n",
    "\n",
    "1. Plot a histogram using Y dataframe and display the per-class data distribution(number of rows per class).\n",
    "2. Also print the number of rows per class as numeric value.\n",
    "\n",
    "**A14** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can create or remove cells as per your need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15** \n",
    "\n",
    "\n",
    "1. From the histogram we can see that the dataset is highly imbalanced.\n",
    "2. Use a proper dataset balancing technique to make the dataset balanced.\n",
    "3. Plot a histogram using new y values and display the per-class data distribution(number of rows per class).\n",
    "\n",
    "```Note:``` Use can use the ```imblearn.over_sampling``` library for this task. But use appropriate strategy for the method.\n",
    "\n",
    "Follow the documentation for details: https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html\n",
    "\n",
    "**A15** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can create or remove cells as per your need\n",
    "\n",
    "?\n",
    "X_res, y_res="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q16** \n",
    "\n",
    "\n",
    "1. Create new Train and Test data from the balaned X and Y value.\n",
    "2. Keep Train and Test ratio as : 75%:25%\n",
    "\n",
    "**A16** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q17**\n",
    "\n",
    "### Now, Use the previously initialized three models and calculate the score from our new balanced dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Number 1** \n",
    "\n",
    "1. Fit the model with the new train data(Use the previous Model 1) \n",
    "2. Get the score from the model using  new test data\n",
    "\n",
    "**A17** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can create or remove cells as per your need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Number 2** \n",
    "\n",
    "1. Fit the model with the new train data(Use the previous Model 2) \n",
    "2. Get the score from the model using  new test data\n",
    "\n",
    "Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can create or remove cells as per your need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Number 3** \n",
    "\n",
    "1. Fit the model with the new train data(Use the previous Model 3) \n",
    "2. Get the score from the model using  new test data\n",
    "\n",
    "Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can create or remove cells as per your need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After making the dataset balanced we can see a significant improve in the performence for all three models."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of CS4347-Assignment2-NETID.ipynb",
   "provenance": [
    {
     "file_id": "1vsORsvIGVbJ2cNHR1lIPDIuGobP25ZPq",
     "timestamp": 1629391503766
    },
    {
     "file_id": "1vuQua73YBPg3xOVKXACAGdS_8R1OlQdX",
     "timestamp": 1611597429764
    },
    {
     "file_id": "1Jr8VoifAgTlPqVE_AiCDeWbiHGEyvkxq",
     "timestamp": 1580784119108
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "6e3520c759e5572dcce85a4d2a3287416a08b75cbd9d64f3e9845a08c03ad027"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
